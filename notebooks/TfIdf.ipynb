{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eee175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Загрузка стоп-слов и стеммера\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Получение текстовых данных из определенной колонки DataFrame\n",
    "documents = (df['analysis_name'] + \" \" + df[\"best_match_synonym\"]).tolist()\n",
    "# documents = f\"{df['analysis_name']} {df[\"best_match_synonym\"]}\"\n",
    "\n",
    "# Загрузка стоп-слов и стеммера\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "# Функция для предобработки текста\n",
    "def preprocess_text(text):\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Предобработка текстовых данных\n",
    "processed_documents = [' '.join(preprocess_text(doc)) for doc in documents]\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Вычисление весов TF-IDF для текстовых данных \n",
    "tfidf_matrix = vectorizer.fit_transform(processed_documents)\n",
    "\n",
    "# Ввод запроса от пользователя \n",
    "query = input(\"Введите запрос: \")\n",
    "\n",
    "# Предобработка запроса \n",
    "processed_query = ' '.join(preprocess_text(query))\n",
    "\n",
    "# Вычисление весов TF-IDF для запроса \n",
    "query_tfidf = vectorizer.transform([processed_query])\n",
    "\n",
    "# Вычисление сходства между запросом и текстовыми данными\n",
    "similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "# Сортировка документов по убыванию значений сходства\n",
    "sorted_indexes = similarities.argsort()[::-1]\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Результаты поиска:\")\n",
    "for index in sorted_indexes:\n",
    "    print(f\"Документ: {documents[index]}, Сходство: {similarities[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>анализ крови на глюкозу глюкоза в плазме или с...</td>\n",
       "      <td>глюкоза в крови glucose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>анализ крови на гликированный гемоглобин glyco...</td>\n",
       "      <td>гликированный гемоглобин hba1с, glycated hemog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>анализ крови на фруктозамин гликозилированный ...</td>\n",
       "      <td>фруктозамин fructosamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>анализ крови на гтт пероральный глюкозотолеран...</td>\n",
       "      <td>глюкозотолерантный тест с определением глюкозы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>анализ крови на толерантность к глюкозе с с-пе...</td>\n",
       "      <td>глюкозотолерантный тест с определением глюкозы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>урогенитальный соскоб на лактобактерии</td>\n",
       "      <td>лактобактерии, определение днк lactobаcillus s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>рентген рентгенография</td>\n",
       "      <td>рентгенография</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>экг электрокардиограмма</td>\n",
       "      <td>электрокардиограмма</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>мрт</td>\n",
       "      <td>магнитно-резонансная томография</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>801</td>\n",
       "      <td>кт компьютерная томография</td>\n",
       "      <td>компьютерная томография</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>802 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                           synonyms  \\\n",
       "0             0  анализ крови на глюкозу глюкоза в плазме или с...   \n",
       "1             1  анализ крови на гликированный гемоглобин glyco...   \n",
       "2             2  анализ крови на фруктозамин гликозилированный ...   \n",
       "3             3  анализ крови на гтт пероральный глюкозотолеран...   \n",
       "4             4  анализ крови на толерантность к глюкозе с с-пе...   \n",
       "..          ...                                                ...   \n",
       "797         797             урогенитальный соскоб на лактобактерии   \n",
       "798         798                             рентген рентгенография   \n",
       "799         799                            экг электрокардиограмма   \n",
       "800         800                                                мрт   \n",
       "801         801                         кт компьютерная томография   \n",
       "\n",
       "                                              analysis  \n",
       "0                              глюкоза в крови glucose  \n",
       "1    гликированный гемоглобин hba1с, glycated hemog...  \n",
       "2                             фруктозамин fructosamine  \n",
       "3    глюкозотолерантный тест с определением глюкозы...  \n",
       "4    глюкозотолерантный тест с определением глюкозы...  \n",
       "..                                                 ...  \n",
       "797  лактобактерии, определение днк lactobаcillus s...  \n",
       "798                                     рентгенография  \n",
       "799                                электрокардиограмма  \n",
       "800                    магнитно-резонансная томография  \n",
       "801                            компьютерная томография  \n",
       "\n",
       "[802 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synonyms = pd.read_csv(\"../data/preprocessed_data/df_reg_sys.csv\")\n",
    "df_analysis  = pd.read_csv(\"../data/preprocessed_data/df_analysis.csv\")\n",
    "df_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3869ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38956208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Tfidf():\n",
    "\n",
    "\n",
    "    def __init__(self, \n",
    "                stemmer: SnowballStemmer = SnowballStemmer(language=\"russian\"), \n",
    "                tokenizer: RegexpTokenizer = RegexpTokenizer(r\"\\w+\"),\n",
    "                vectorizer: TfidfVectorizer = TfidfVectorizer()\n",
    "                ):\n",
    "        self.stemmer = stemmer\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vectorizer = vectorizer\n",
    "        self.tfidf_matrix = np.ndarray([])\n",
    "    \n",
    "    @classmethod\n",
    "    def stop_words(cls) -> set:\n",
    "        stop_words = set(stopwords.words('russian'))\n",
    "        custom_stop_words = (\"анализ\", \"уровень\", \"определение\", \"анализы\", \"консультация\", \"выявление\")\n",
    "        return set(stop_words.union(custom_stop_words))\n",
    "    \n",
    "    def concatenate_values(self, row):\n",
    "        return ' '.join(row)\n",
    "\n",
    "    def get_documents(self, df: pd.DataFrame) -> list:\n",
    "        # Получение текстовых данных из определенных колонок DataFrame\n",
    "        df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n",
    "        return df[\"concatenated\"].tolist()\n",
    "\n",
    "        # Функция для предобработки текста\n",
    "    def preprocess_text(self, text):\n",
    "        tokens = self.tokenizer.tokenize(text.lower())\n",
    "        tokens = [token for token in tokens if token not in Model_Tfidf.stop_words()]\n",
    "        stemmed_tokens = [self.stemmer.stem(token) for token in tokens]\n",
    "        return stemmed_tokens\n",
    "\n",
    "    # Предобработка текстовых данных\n",
    "    def preprocessed_documents(self, df: pd.DataFrame):\n",
    "        documents = self.get_documents(df)\n",
    "        return [' '.join(self.preprocess_text(doc)) for doc in documents]\n",
    "\n",
    "    # Предобработка запроса \n",
    "    def preprocessed_query(self, query:str):\n",
    "        return ' '.join(self.preprocess_text(query))\n",
    "\n",
    "    def get_similar_synonyms(self, df: pd.DataFrame, df_synonyms: pd.DataFrame):\n",
    "        tfidf_synonyms = self.vectorizer.fit_transform(self.preprocessed_documents(df_synonyms[[\"analysis\"]])) \n",
    "        tfidf_df = self.vectorizer.transform(self.preprocessed_documents(df[[\"analysis_name\"]]))\n",
    "        syn_indexes = []\n",
    "        syn_similarity = []\n",
    "        # Вычисление сходства между запросом и текстовыми данными\n",
    "        for vec in tfidf_df:\n",
    "            similarities = cosine_similarity(vec, tfidf_synonyms).flatten()\n",
    "            # Сортировка документов по убыванию значений сходства\n",
    "            sorted_indexes = similarities.argsort()[::-1]\n",
    "            syn_indexes.append(sorted_indexes[0])\n",
    "            syn_similarity.append(similarities[sorted_indexes[0]])\n",
    "\n",
    "        df_similarity = pd.DataFrame({\n",
    "                                        \"best_match_synonym\": df_synonyms[\"synonyms\"].iloc[syn_indexes].values,\n",
    "                                        \"best_match_analysis\": df_synonyms[\"analysis\"].iloc[syn_indexes].values,\n",
    "                                        \"similarity\": syn_similarity\n",
    "                                    }, index=df.index).sort_index(ascending=False)\n",
    "        \n",
    "        df_result = pd.concat((df, df_similarity), axis=1)\n",
    "        df_result.loc[(df_result[\"similarity\"] < 0.64), (\"best_match_synonym\", \"best_match_analysis\")] = \"\"\n",
    "        return df_result\n",
    "    \n",
    "\n",
    "    def get_similar_analysis(self, df: pd.DataFrame, query: str ):\n",
    "        \n",
    "        df.loc[(df[\"best_match_synonym\"].isnull()), (\"best_match_synonym\", \"best_match_analysis\")] = \"\"\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.preprocessed_documents(df[[\"analysis_name\", \"best_match_synonym\"]]))\n",
    "        tfidf_query = self.vectorizer.transform([self.preprocessed_query(query)])\n",
    "\n",
    "        similarities = cosine_similarity(tfidf_query, self.tfidf_matrix).flatten()\n",
    "        # Сортировка документов по убыванию значений сходства\n",
    "        sorted_indexes = similarities.argsort()[::-1]\n",
    "        \n",
    "        df[\"as\"] = similarities            \n",
    "                \n",
    "        return df[[\"source\", \"analysis_name\", \"analysis_cost\"]].iloc[sorted_indexes].loc[df[\"as\"] >= 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2f7a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model_Tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad297a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4325/1005747622.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n",
      "/tmp/ipykernel_4325/1005747622.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n"
     ]
    }
   ],
   "source": [
    "df = m.get_similar_synonyms(df=df_analysis, df_synonyms=df_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab5a25ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter</th>\n",
       "      <th>analysis_name</th>\n",
       "      <th>analysis_cost</th>\n",
       "      <th>analysis_comment</th>\n",
       "      <th>best_match_synonym</th>\n",
       "      <th>best_match_analysis</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6gkb.by</td>\n",
       "      <td>Лабораторная диагностика</td>\n",
       "      <td>общий анализ мочи пункты 1 2 + 2 1 9 + 2 1 4 1...</td>\n",
       "      <td>5.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>клинический анализ мочи оам complete urinalysi...</td>\n",
       "      <td>анализ мочи общий анализ мочи с микроскопией о...</td>\n",
       "      <td>0.702894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>6gkb.by</td>\n",
       "      <td>Лабораторная диагностика</td>\n",
       "      <td>подсчет тромбоцитов крови в окрашеных мазках п...</td>\n",
       "      <td>3.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>анализ крови на тромбоциты тромбоциты, микроск...</td>\n",
       "      <td>тромбоциты, микроскопия подсчет в окрашенном м...</td>\n",
       "      <td>0.862644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>6gkb.by</td>\n",
       "      <td>Лабораторная диагностика</td>\n",
       "      <td>са 242*</td>\n",
       "      <td>16.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>анализ крови на са-242 углеводный антиген 242 ...</td>\n",
       "      <td>ca-242 углеводный антиген са-242, опухолевый м...</td>\n",
       "      <td>0.705643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>6gkb.by</td>\n",
       "      <td>Лабораторная диагностика</td>\n",
       "      <td>определение кальцитонина</td>\n",
       "      <td>18.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>анализ крови на кальцитонин тиреокальцитонин т...</td>\n",
       "      <td>кальцитонин calcitonin</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>6gkb.by</td>\n",
       "      <td>Лабораторная диагностика</td>\n",
       "      <td>холестерин высокой плотности лпвп hdl биохимич...</td>\n",
       "      <td>1.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>липопротеиды высокой плотности лпвп лвп хс лпв...</td>\n",
       "      <td>холестерин-лпвп холестерин липопротеинов высок...</td>\n",
       "      <td>0.757359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>4893</td>\n",
       "      <td>4977</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>фруктозамин fructosamine</td>\n",
       "      <td>3.99</td>\n",
       "      <td>Фруктозамин - комплекс глюкозы с белками крови...</td>\n",
       "      <td>анализ крови на фруктозамин гликозилированный ...</td>\n",
       "      <td>фруктозамин fructosamine</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>4909</td>\n",
       "      <td>4993</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>выявление антител класса igg к yersinia entero...</td>\n",
       "      <td>10.20</td>\n",
       "      <td>Выявление антител класса IgG к Yersinia Entero...</td>\n",
       "      <td>специфические иммуноглобулины класса igg к бак...</td>\n",
       "      <td>антитела класса  igg к антигенам yersinia ente...</td>\n",
       "      <td>0.806810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>4916</td>\n",
       "      <td>5000</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>гонококк , определение днк neisseria gonorrhoe...</td>\n",
       "      <td>11.26</td>\n",
       "      <td>Тест для определения генетического материала (...</td>\n",
       "      <td>гонококк, определение днк в моче возбудитель г...</td>\n",
       "      <td>гонококк, определение днк neisseria gonorrhoea...</td>\n",
       "      <td>0.794828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>4918</td>\n",
       "      <td>5002</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>антитела igm к бета2 - гликопротеину i</td>\n",
       "      <td>13.23</td>\n",
       "      <td>Важный показатель в диагностике антифосфолипид...</td>\n",
       "      <td>анализ крови на igm антитела к бета-2-гликопро...</td>\n",
       "      <td>антитела к бета-2-гликопротеину, igm anti-beta...</td>\n",
       "      <td>0.708758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>4924</td>\n",
       "      <td>5008</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>антитела класса igg к тканевой трансглютаминаз...</td>\n",
       "      <td>14.15</td>\n",
       "      <td>Определение в сыворотке крови иммуноглобулинов...</td>\n",
       "      <td>анализ крови на антитела класса igg к тканевой...</td>\n",
       "      <td>антитела класса igg к тканевой трансглютаминаз...</td>\n",
       "      <td>0.965595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index   source                   chapter  \\\n",
       "5              5      5  6gkb.by  Лабораторная диагностика   \n",
       "63            63     63  6gkb.by  Лабораторная диагностика   \n",
       "84            84     84  6gkb.by  Лабораторная диагностика   \n",
       "87            87     87  6gkb.by  Лабораторная диагностика   \n",
       "95            95     95  6gkb.by  Лабораторная диагностика   \n",
       "...          ...    ...      ...                       ...   \n",
       "4893        4893   4977  Lode.by                       NaN   \n",
       "4909        4909   4993  Lode.by                       NaN   \n",
       "4916        4916   5000  Lode.by                       NaN   \n",
       "4918        4918   5002  Lode.by                       NaN   \n",
       "4924        4924   5008  Lode.by                       NaN   \n",
       "\n",
       "                                          analysis_name  analysis_cost  \\\n",
       "5     общий анализ мочи пункты 1 2 + 2 1 9 + 2 1 4 1...           5.51   \n",
       "63    подсчет тромбоцитов крови в окрашеных мазках п...           3.34   \n",
       "84                                              са 242*          16.99   \n",
       "87                             определение кальцитонина          18.09   \n",
       "95    холестерин высокой плотности лпвп hdl биохимич...           1.65   \n",
       "...                                                 ...            ...   \n",
       "4893                           фруктозамин fructosamine           3.99   \n",
       "4909  выявление антител класса igg к yersinia entero...          10.20   \n",
       "4916  гонококк , определение днк neisseria gonorrhoe...          11.26   \n",
       "4918             антитела igm к бета2 - гликопротеину i          13.23   \n",
       "4924  антитела класса igg к тканевой трансглютаминаз...          14.15   \n",
       "\n",
       "                                       analysis_comment  \\\n",
       "5                                                   NaN   \n",
       "63                                                  NaN   \n",
       "84                                                  NaN   \n",
       "87                                                  NaN   \n",
       "95                                                  NaN   \n",
       "...                                                 ...   \n",
       "4893  Фруктозамин - комплекс глюкозы с белками крови...   \n",
       "4909  Выявление антител класса IgG к Yersinia Entero...   \n",
       "4916  Тест для определения генетического материала (...   \n",
       "4918  Важный показатель в диагностике антифосфолипид...   \n",
       "4924  Определение в сыворотке крови иммуноглобулинов...   \n",
       "\n",
       "                                     best_match_synonym  \\\n",
       "5     клинический анализ мочи оам complete urinalysi...   \n",
       "63    анализ крови на тромбоциты тромбоциты, микроск...   \n",
       "84    анализ крови на са-242 углеводный антиген 242 ...   \n",
       "87    анализ крови на кальцитонин тиреокальцитонин т...   \n",
       "95    липопротеиды высокой плотности лпвп лвп хс лпв...   \n",
       "...                                                 ...   \n",
       "4893  анализ крови на фруктозамин гликозилированный ...   \n",
       "4909  специфические иммуноглобулины класса igg к бак...   \n",
       "4916  гонококк, определение днк в моче возбудитель г...   \n",
       "4918  анализ крови на igm антитела к бета-2-гликопро...   \n",
       "4924  анализ крови на антитела класса igg к тканевой...   \n",
       "\n",
       "                                    best_match_analysis  similarity  \n",
       "5     анализ мочи общий анализ мочи с микроскопией о...    0.702894  \n",
       "63    тромбоциты, микроскопия подсчет в окрашенном м...    0.862644  \n",
       "84    ca-242 углеводный антиген са-242, опухолевый м...    0.705643  \n",
       "87                               кальцитонин calcitonin    0.707107  \n",
       "95    холестерин-лпвп холестерин липопротеинов высок...    0.757359  \n",
       "...                                                 ...         ...  \n",
       "4893                           фруктозамин fructosamine    1.000000  \n",
       "4909  антитела класса  igg к антигенам yersinia ente...    0.806810  \n",
       "4916  гонококк, определение днк neisseria gonorrhoea...    0.794828  \n",
       "4918  антитела к бета-2-гликопротеину, igm anti-beta...    0.708758  \n",
       "4924  антитела класса igg к тканевой трансглютаминаз...    0.965595  \n",
       "\n",
       "[892 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"similarity\"] > 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f64b43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4325/1129943349.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n",
      "/tmp/ipykernel_4325/1129943349.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n"
     ]
    }
   ],
   "source": [
    "a = m.get_documents(df_analysis[[\"analysis_name\"]])\n",
    "s = m.get_documents(df_synonyms[[\"analysis\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd42b21a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 1: expected str instance, float found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manalysis_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_match_synonym\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 37\u001b[0m, in \u001b[0;36mModel_Tfidf.preprocessed_documents\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocessed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m---> 37\u001b[0m     documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_text(doc)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "Cell \u001b[0;32mIn[56], line 25\u001b[0m, in \u001b[0;36mModel_Tfidf.get_documents\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, df: pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Получение текстовых данных из определенных колонок DataFrame\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcatenated\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconcatenated\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/pp/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pp/lib/python3.10/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pp/lib/python3.10/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/pp/lib/python3.10/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[56], line 21\u001b[0m, in \u001b[0;36mModel_Tfidf.concatenate_values\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, row):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 1: expected str instance, float found"
     ]
    }
   ],
   "source": [
    "m.preprocessed_documents(df[[\"analysis_name\", \"best_match_synonym\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4e2b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4325/185580246.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['concatenated'] = df.apply(self.concatenate_values, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>analysis_name</th>\n",
       "      <th>analysis_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>Lode.by</td>\n",
       "      <td>эозинофильный катионный белок экб, еср</td>\n",
       "      <td>56.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Synevo.by</td>\n",
       "      <td>эозинофильный катионный белок ecp 08-094</td>\n",
       "      <td>56.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source                             analysis_name  analysis_cost\n",
       "4343    Lode.by    эозинофильный катионный белок экб, еср          56.72\n",
       "2124  Synevo.by  эозинофильный катионный белок ecp 08-094          56.72"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_similar_analysis(df, \"экб\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105e1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0f7343f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>source</th>\n",
       "      <th>chapter</th>\n",
       "      <th>analysis_name</th>\n",
       "      <th>analysis_cost</th>\n",
       "      <th>analysis_comment</th>\n",
       "      <th>best_match_synonym</th>\n",
       "      <th>best_match_analysis</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>4818</td>\n",
       "      <td>4902</td>\n",
       "      <td>Lode.by</td>\n",
       "      <td>NaN</td>\n",
       "      <td>посев раневого отделяемого и тканей на микрофл...</td>\n",
       "      <td>29.6</td>\n",
       "      <td>Микробиологическое иследование на определение ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>посев раневого отделяемого и тканей на микрофл...</td>\n",
       "      <td>0.799534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index   source chapter  \\\n",
       "4818        4818   4902  Lode.by     NaN   \n",
       "\n",
       "                                          analysis_name  analysis_cost  \\\n",
       "4818  посев раневого отделяемого и тканей на микрофл...           29.6   \n",
       "\n",
       "                                       analysis_comment best_match_synonym  \\\n",
       "4818  Микробиологическое иследование на определение ...                NaN   \n",
       "\n",
       "                                    best_match_analysis  similarity  \n",
       "4818  посев раневого отделяемого и тканей на микрофл...    0.799534  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"best_match_synonym\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078630d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
